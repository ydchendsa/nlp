{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport transformers\n\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import DataCollatorWithPadding\nfrom transformers import logging as hf_logging\nhf_logging.set_verbosity_error()\n\nfrom datasets import Dataset\n\nimport os\nimport gc\nimport sys\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:44:31.770140Z","iopub.execute_input":"2022-11-30T14:44:31.770533Z","iopub.status.idle":"2022-11-30T14:44:48.045136Z","shell.execute_reply.started":"2022-11-30T14:44:31.770494Z","shell.execute_reply":"2022-11-30T14:44:48.044074Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Set Configs","metadata":{}},{"cell_type":"code","source":"CONFIG = {\n        'folds': 5,\n        'seed': 101,\n        'robertabase': '../input/huggingface-roberta-variants/roberta-base/roberta-base',\n        'robertalarge': '../input/huggingface-roberta-variants/roberta-large/roberta-large',\n        #'debertav3base': '../input/debertav3base',\n        #'debertav3large': '../input/deberta-v3-large/deberta-v3-large/',\n        'xlmrobertabase': '../input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base',\n        'distilrobertabase': '../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base',\n        #'debertav3large_npy': '../input/fb3-save-pretrained-embeddings/debertav3large_FB3.npy',\n        #'distilrobertabase_npy': '../input/fb3-save-pretrained-embeddings/distilrobertabase_FB3.npy',\n\n        'batch_size': 4,\n        'max_len': 512\n        }","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:45.555893Z","iopub.execute_input":"2022-11-30T00:10:45.556573Z","iopub.status.idle":"2022-11-30T00:10:45.568948Z","shell.execute_reply.started":"2022-11-30T00:10:45.556523Z","shell.execute_reply":"2022-11-30T00:10:45.564678Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Read in data","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n       os.path.join(dirname, filename)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:45.572552Z","iopub.execute_input":"2022-11-30T00:10:45.573157Z","iopub.status.idle":"2022-11-30T00:10:45.709196Z","shell.execute_reply.started":"2022-11-30T00:10:45.573122Z","shell.execute_reply":"2022-11-30T00:10:45.708383Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#df = pd.read_csv(\"/kaggle/input/large580/train_20000.csv\")\n#msk = np.random.rand(len(df)) <= 0.9\n#tgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n#train = df[msk].dropna()\n#test = df[~msk].dropna()\n#test = pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:45.710265Z","iopub.execute_input":"2022-11-30T00:10:45.710519Z","iopub.status.idle":"2022-11-30T00:10:45.715348Z","shell.execute_reply.started":"2022-11-30T00:10:45.710495Z","shell.execute_reply":"2022-11-30T00:10:45.714364Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\ntrain = pd.read_csv(\"../input/feedback-prize-english-language-learning/train.csv\")\n#test = pd.read_csv(\"/kaggle/input/580data/test.csv\")\ntest = pd.read_csv(\"/kaggle/input/580data/test_balanced.csv\")\ntgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n#train = train[['text_id','full_text','cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']]\n#test = test[['text_id','full_text','cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']]\nprint(train.shape)\nprint(test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:45.718822Z","iopub.execute_input":"2022-11-30T00:10:45.719474Z","iopub.status.idle":"2022-11-30T00:10:45.964284Z","shell.execute_reply.started":"2022-11-30T00:10:45.719437Z","shell.execute_reply":"2022-11-30T00:10:45.962949Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(3911, 8)\n(783, 11)\n","output_type":"stream"}]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:45.965729Z","iopub.execute_input":"2022-11-30T00:10:45.966373Z","iopub.status.idle":"2022-11-30T00:10:46.001514Z","shell.execute_reply.started":"2022-11-30T00:10:45.966334Z","shell.execute_reply":"2022-11-30T00:10:46.000619Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     Unnamed: 0       text_id  \\\n0           272  13C400DD9794   \n1          3051  D9BC7F4F22F0   \n2           800  3E170458E9A1   \n3          3206  E0BFF1488787   \n4          2664  C50BE3C76571   \n..          ...           ...   \n778        2207  A4A90A401002   \n779        2747  CA11FD3CAC43   \n780         155  0BB9FAE6E27B   \n781        3464  ED0A8E614649   \n782        2318  ACA1A45EE438   \n\n                                             full_text  cohesion  syntax  \\\n0    The year book is for to not forget anything an...       2.0     2.0   \n1    Well what i think about praising for a student...       2.5     2.5   \n2    I\\n\\ndisagree that first impressions are almos...       2.0     2.0   \n3    I disagree with schools having a program with ...       2.5     2.0   \n4    I dont like becuase the student forget all inf...       3.0     2.5   \n..                                                 ...       ...     ...   \n778  People who value self-reliance define it as th...       3.0     3.5   \n779  Many people have been told about the fact that...       4.5     4.0   \n780  Setting A Good Example\\n\\nHave you thought of ...       3.5     4.0   \n781  Techonology has becoming powerful that let stu...       4.5     3.5   \n782  I strongly disagree with extending the school ...       4.0     3.0   \n\n     vocabulary  phraseology  grammar  conventions  average  bin  \n0           2.0          2.0      2.0          2.0      2.0    0  \n1           2.5          3.0      2.5          2.0      2.5    0  \n2           2.0          2.0      2.0          2.5      2.1    0  \n3           2.5          2.0      2.0          2.5      2.3    0  \n4           2.0          2.0      2.0          2.5      2.4    0  \n..          ...          ...      ...          ...      ...  ...  \n778         3.5          4.0      3.5          4.0      3.6    2  \n779         3.5          4.0      3.5          3.5      3.9    2  \n780         4.5          4.0      3.5          3.5      3.9    2  \n781         4.0          4.0      4.0          3.5      3.9    2  \n782         3.0          4.0      4.0          4.0      3.6    2  \n\n[783 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>average</th>\n      <th>bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>272</td>\n      <td>13C400DD9794</td>\n      <td>The year book is for to not forget anything an...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3051</td>\n      <td>D9BC7F4F22F0</td>\n      <td>Well what i think about praising for a student...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>800</td>\n      <td>3E170458E9A1</td>\n      <td>I\\n\\ndisagree that first impressions are almos...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3206</td>\n      <td>E0BFF1488787</td>\n      <td>I disagree with schools having a program with ...</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2664</td>\n      <td>C50BE3C76571</td>\n      <td>I dont like becuase the student forget all inf...</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>2207</td>\n      <td>A4A90A401002</td>\n      <td>People who value self-reliance define it as th...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>2747</td>\n      <td>CA11FD3CAC43</td>\n      <td>Many people have been told about the fact that...</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>155</td>\n      <td>0BB9FAE6E27B</td>\n      <td>Setting A Good Example\\n\\nHave you thought of ...</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>3464</td>\n      <td>ED0A8E614649</td>\n      <td>Techonology has becoming powerful that let stu...</td>\n      <td>4.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>2318</td>\n      <td>ACA1A45EE438</td>\n      <td>I strongly disagree with extending the school ...</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"my_list = train.columns.values.tolist()\nmy_list","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.003063Z","iopub.execute_input":"2022-11-30T00:10:46.003426Z","iopub.status.idle":"2022-11-30T00:10:46.012483Z","shell.execute_reply.started":"2022-11-30T00:10:46.003391Z","shell.execute_reply":"2022-11-30T00:10:46.011294Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['text_id',\n 'full_text',\n 'cohesion',\n 'syntax',\n 'vocabulary',\n 'phraseology',\n 'grammar',\n 'conventions']"},"metadata":{}}]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.013992Z","iopub.execute_input":"2022-11-30T00:10:46.015045Z","iopub.status.idle":"2022-11-30T00:10:46.037811Z","shell.execute_reply.started":"2022-11-30T00:10:46.015011Z","shell.execute_reply":"2022-11-30T00:10:46.036692Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     0016926B079C  I think that students would benefit from learn...   \n1     0022683E9EA5  When a problem is a change you have to let it ...   \n2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n3     003885A45F42  The best time in life is when you become yours...   \n4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n...            ...                                                ...   \n3906  FFD29828A873  I believe using cellphones in class for educat...   \n3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n0          3.5     3.5         3.0          3.0      4.0          3.0  \n1          2.5     2.5         3.0          2.0      2.0          2.5  \n2          3.0     3.5         3.0          3.0      3.0          2.5  \n3          4.5     4.5         4.5          4.5      4.0          5.0  \n4          2.5     3.0         3.0          3.0      2.5          2.5  \n...        ...     ...         ...          ...      ...          ...  \n3906       2.5     3.0         3.0          3.5      2.5          2.5  \n3907       4.0     4.0         4.0          4.0      3.5          3.0  \n3908       2.5     3.0         3.0          3.0      3.5          3.0  \n3909       4.0     4.5         4.5          4.0      4.5          4.5  \n3910       3.5     2.5         3.5          3.0      3.0          3.5  \n\n[3911 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3906</th>\n      <td>FFD29828A873</td>\n      <td>I believe using cellphones in class for educat...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>FFD9A83B0849</td>\n      <td>Working alone, students do not have to argue w...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3908</th>\n      <td>FFDC4011AC9C</td>\n      <td>\"A problem is a chance for you to do your best...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>FFE16D704B16</td>\n      <td>Many people disagree with Albert Schweitzer's ...</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>FFED00D6E0BD</td>\n      <td>Do you think that failure is the main thing fo...</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>3911 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create folds","metadata":{}},{"cell_type":"code","source":"train.loc[:, 'kfold'] = -1 # Create a new column `fold` containing `-1`s.\ntrain = train.sample(frac=1).reset_index(drop=True) # Shuffle the rows.\ndata_labels = train[tgtCols].values","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.039310Z","iopub.execute_input":"2022-11-30T00:10:46.039729Z","iopub.status.idle":"2022-11-30T00:10:46.054799Z","shell.execute_reply.started":"2022-11-30T00:10:46.039696Z","shell.execute_reply":"2022-11-30T00:10:46.053904Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.056070Z","iopub.execute_input":"2022-11-30T00:10:46.057112Z","iopub.status.idle":"2022-11-30T00:10:46.074306Z","shell.execute_reply.started":"2022-11-30T00:10:46.057076Z","shell.execute_reply":"2022-11-30T00:10:46.073436Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"mskf = MultilabelStratifiedKFold(n_splits=5)\nfor f, (t, v) in enumerate(mskf.split(X=train, y=data_labels)):\n    train.loc[v, 'kfold'] = f + 1","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.076302Z","iopub.execute_input":"2022-11-30T00:10:46.077189Z","iopub.status.idle":"2022-11-30T00:10:46.213542Z","shell.execute_reply.started":"2022-11-30T00:10:46.077156Z","shell.execute_reply":"2022-11-30T00:10:46.212669Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.215211Z","iopub.execute_input":"2022-11-30T00:10:46.215597Z","iopub.status.idle":"2022-11-30T00:10:46.239598Z","shell.execute_reply.started":"2022-11-30T00:10:46.215561Z","shell.execute_reply":"2022-11-30T00:10:46.238552Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"           text_id                                          full_text  \\\n0     4E22E3143561  Agree, living in a world where you sometimes h...   \n1     E21D14227555  A wise man once said ''the usage of technology...   \n2     BF267B42A2A4  The humanity now in days had been not so good ...   \n3     B5AE26EEE247  Do you think that having a positive attitude i...   \n4     6013DA298542  Schools have partnered with local companies to...   \n...            ...                                                ...   \n3906  00D281524375  Technology allows people to do many things suc...   \n3907  D242BBCBEAFB  Some student can take classes at home because ...   \n3908  EBE0730AFF0E  Adopting the failure is the way to become mast...   \n3909  D86C20117DC9  Students should work in groups or should works...   \n3910  F78366DD5A31  The decision regarding extracurricular involve...   \n\n      cohesion  syntax  vocabulary  phraseology  grammar  conventions  kfold  \n0          3.0     3.0         3.5          3.5      3.0          3.5      3  \n1          3.5     3.5         3.5          3.5      3.5          3.0      5  \n2          3.0     3.0         3.0          3.5      3.5          3.5      2  \n3          4.0     3.5         3.5          3.5      3.5          3.5      1  \n4          2.0     2.5         3.0          3.0      3.0          2.5      4  \n...        ...     ...         ...          ...      ...          ...    ...  \n3906       3.5     2.5         3.5          3.0      3.0          3.0      1  \n3907       2.5     2.5         2.5          2.5      2.5          2.5      4  \n3908       3.5     2.5         3.5          3.5      2.5          2.5      3  \n3909       4.0     4.0         3.5          3.5      3.5          3.0      5  \n3910       4.0     4.0         3.5          4.0      4.0          4.5      4  \n\n[3911 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4E22E3143561</td>\n      <td>Agree, living in a world where you sometimes h...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E21D14227555</td>\n      <td>A wise man once said ''the usage of technology...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BF267B42A2A4</td>\n      <td>The humanity now in days had been not so good ...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B5AE26EEE247</td>\n      <td>Do you think that having a positive attitude i...</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6013DA298542</td>\n      <td>Schools have partnered with local companies to...</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3906</th>\n      <td>00D281524375</td>\n      <td>Technology allows people to do many things suc...</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>D242BBCBEAFB</td>\n      <td>Some student can take classes at home because ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3908</th>\n      <td>EBE0730AFF0E</td>\n      <td>Adopting the failure is the way to become mast...</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3909</th>\n      <td>D86C20117DC9</td>\n      <td>Students should work in groups or should works...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>F78366DD5A31</td>\n      <td>The decision regarding extracurricular involve...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>3911 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['kfold'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.240959Z","iopub.execute_input":"2022-11-30T00:10:46.241417Z","iopub.status.idle":"2022-11-30T00:10:46.252599Z","shell.execute_reply.started":"2022-11-30T00:10:46.241373Z","shell.execute_reply":"2022-11-30T00:10:46.251565Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1    782\n2    782\n3    782\n4    783\n5    782\nName: kfold, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data process functions","metadata":{}},{"cell_type":"code","source":"def self_encode(texts, chkpt):\n    \n    tokenizer = transformers.AutoTokenizer.from_pretrained(CONFIG[chkpt])\n    tokenizer.save_pretrained('./tokenizer/')\n\n    input_ids = []\n    attention_mask = []\n    \n    for text in texts.tolist():\n        token = tokenizer(text, \n                          add_special_tokens=True, \n                          max_length=CONFIG['max_len'], \n                          return_attention_mask=True, \n                          return_tensors=\"np\", \n                          truncation=True, \n                          padding='max_length')\n        input_ids.append(token['input_ids'][0])\n        attention_mask.append(token['attention_mask'][0])\n    return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.259254Z","iopub.execute_input":"2022-11-30T00:10:46.259654Z","iopub.status.idle":"2022-11-30T00:10:46.268208Z","shell.execute_reply.started":"2022-11-30T00:10:46.259596Z","shell.execute_reply":"2022-11-30T00:10:46.267231Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def pickle_dump(path, saveobj):\n    import pickle\n    handler = open(path,\"wb\")\n    pickle.dump(saveobj,handler)\n#     print(\"File pickled\")\n    handler.close()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.271118Z","iopub.execute_input":"2022-11-30T00:10:46.271374Z","iopub.status.idle":"2022-11-30T00:10:46.280432Z","shell.execute_reply.started":"2022-11-30T00:10:46.271351Z","shell.execute_reply":"2022-11-30T00:10:46.279411Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def pickle_load(path):\n    import pickle\n    file = open(path,'rb')\n    loader = pickle.load(file)\n    file.close()\n    return loader","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.281942Z","iopub.execute_input":"2022-11-30T00:10:46.282365Z","iopub.status.idle":"2022-11-30T00:10:46.295535Z","shell.execute_reply.started":"2022-11-30T00:10:46.282328Z","shell.execute_reply":"2022-11-30T00:10:46.294691Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Transformer embeddings","metadata":{}},{"cell_type":"code","source":"def pretrain_embeddings(chkpt, df):\n    cfg = transformers.AutoConfig.from_pretrained(CONFIG[chkpt], output_hidden_states=True)\n    cfg.hidden_dropout_prob = 0\n    cfg.attention_probs_dropout_prob = 0\n    cfg.save_pretrained('./tokenizer/')\n    \n    input_ids = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"input_ids\"\n    )\n    \n    attention_masks = tf.keras.layers.Input(\n        shape=(CONFIG['max_len'],), dtype=tf.int32, name=\"attention_masks\"\n    )\n    \n    try:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg)\n    except:\n        model = transformers.TFAutoModel.from_pretrained(CONFIG[chkpt], config=cfg, from_pt=True)\n        \n    output = model(\n        input_ids, attention_mask=attention_masks\n    )\n    hidden_states = output.hidden_states\n    mean_pool = []\n    for hidden_s in hidden_states[-1:]:\n        #def call(self, inputs, mask=None):\n        broadcast_mask = tf.expand_dims(tf.cast(attention_masks, \"float32\"), -1)\n        embedding_sum = tf.reduce_sum(hidden_s * broadcast_mask, axis=1)\n        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n        tmp = embedding_sum / mask_sum\n        mean_pool.append(tmp)\n    output = tf.stack(mean_pool,axis=2)\n   \n    #output = tf.stack(\n    #    [MeanPool()(hidden_s, mask=attention_masks) for hidden_s in hidd20000en_states[-1:]], \n    #    axis=2)\n    \n    output = tf.squeeze(output, axis=-1)\n    \n    model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n\n    model.compile(optimizer=\"adam\",\n                 loss='huber_loss',\n                 metrics=[tf.keras.metrics.RootMeanSquaredError()],\n                 )\n    print(model.summary())\n    dataset = self_encode(df['full_text'], chkpt)\n    preds = model.predict(dataset, batch_size=CONFIG['batch_size'])\n    \n    del model, dataset\n    _ = gc.collect()\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.297603Z","iopub.execute_input":"2022-11-30T00:10:46.298303Z","iopub.status.idle":"2022-11-30T00:10:46.310743Z","shell.execute_reply.started":"2022-11-30T00:10:46.298270Z","shell.execute_reply":"2022-11-30T00:10:46.309915Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"\ntrain_data = pretrain_embeddings('distilrobertabase', train)\n\n#train_data = np.concatenate([train_data, pretrain_embeddings('bertbasecased', train)], axis=1)\ntrain_data = np.concatenate([train_data, pretrain_embeddings('robertabase', train)], axis=1)\ntrain_data = np.concatenate([train_data, pretrain_embeddings('robertalarge', train)], axis=1)\n\ntrain_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:10:46.312961Z","iopub.execute_input":"2022-11-30T00:10:46.313903Z","iopub.status.idle":"2022-11-30T00:25:29.675833Z","shell.execute_reply.started":"2022-11-30T00:10:46.313843Z","shell.execute_reply":"2022-11-30T00:25:29.674662Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2022-11-30 00:10:46.561274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.562230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.563258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.564011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.564744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.565456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.567375: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-30 00:10:46.832009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.832926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.833755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.834799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.835509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:46.836216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:53.808209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:53.809159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:53.809957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:53.810713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:53.811497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:53.812202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-11-30 00:10:53.815424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 00:10:53.816182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast (TFOpLambda)            (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model (TFRobertaMode TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims (TFOpLambda)     (None, 512, 1)       0           tf.cast[0][0]                    \n__________________________________________________________________________________________________\ntf.math.multiply (TFOpLambda)   (None, 512, 768)     0           tf_roberta_model[0][6]           \n                                                                 tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum_1 (TFOpLambd (None, 1)            0           tf.expand_dims[0][0]             \n__________________________________________________________________________________________________\ntf.math.reduce_sum (TFOpLambda) (None, 768)          0           tf.math.multiply[0][0]           \n__________________________________________________________________________________________________\ntf.math.maximum (TFOpLambda)    (None, 1)            0           tf.math.reduce_sum_1[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv (TFOpLambda)    (None, 768)          0           tf.math.reduce_sum[0][0]         \n                                                                 tf.math.maximum[0][0]            \n__________________________________________________________________________________________________\ntf.stack (TFOpLambda)           (None, 768, 1)       0           tf.math.truediv[0][0]            \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze (TFOpLambd (None, 768)          0           tf.stack[0][0]                   \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"name":"stderr","text":"2022-11-30 00:11:12.252824: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_1 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_1 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_1 (TFOpLambda)   (None, 512, 1)       0           tf.cast_1[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_1 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_1[0][12]        \n                                                                 tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_3 (TFOpLambd (None, 1)            0           tf.expand_dims_1[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_2 (TFOpLambd (None, 768)          0           tf.math.multiply_1[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_1 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_3[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_1 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_2[0][0]       \n                                                                 tf.math.maximum_1[0][0]          \n__________________________________________________________________________________________________\ntf.stack_1 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_1[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_1 (TFOpLam (None, 768)          0           tf.stack_1[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_2 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_2 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_2 (TFOpLambda)   (None, 512, 1)       0           tf.cast_2[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_2 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_2[0][24]        \n                                                                 tf.expand_dims_2[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_5 (TFOpLambd (None, 1)            0           tf.expand_dims_2[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_4 (TFOpLambd (None, 1024)         0           tf.math.multiply_2[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_2 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_5[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_2 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_4[0][0]       \n                                                                 tf.math.maximum_2[0][0]          \n__________________________________________________________________________________________________\ntf.stack_2 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_2[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_2 (TFOpLam (None, 1024)         0           tf.stack_2[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(3911, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"scores = []\nrmse_scores = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('-'*35)\n    print(f'## Fold {fold}')\n    print('-'*35)\n\n    trn_idx = train[train['kfold']==fold].index.values\n    val_idx = train[train['kfold']!=fold].index.values\n    print(f\"trn_idx len is {len(trn_idx)}\")\n\n    X_train = train_data[trn_idx,:]\n    X_valid = train_data[val_idx,:]\n\n    y_train = train[train['kfold']==fold][tgtCols].copy()\n    y_valid = train[train['kfold']!=fold][tgtCols].copy()\n\n    val_preds = np.zeros((len(val_idx),6))\n\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        clf = SVR(C=10)\n        clf.fit(X_train, y_train[tgt].values)\n        pickle_dump(f\"./SVR_tgt{tgt}_fold{fold}.pkl\", clf)\n        val_preds[:,i] = clf.predict(X_valid)\n   \n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('-'*35)\n    print('Overall CV RMSE =',np.mean(scores))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:25:29.677864Z","iopub.execute_input":"2022-11-30T00:25:29.679018Z","iopub.status.idle":"2022-11-30T00:27:04.370084Z","shell.execute_reply.started":"2022-11-30T00:25:29.678975Z","shell.execute_reply":"2022-11-30T00:27:04.368863Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"-----------------------------------\n## Fold 1\n-----------------------------------\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.4667085991638542\n-----------------------------------\nOverall CV RMSE = 0.473426100886325\n-----------------------------------\n## Fold 2\n-----------------------------------\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.470851926925759\n-----------------------------------\nOverall CV RMSE = 0.4720277924698781\n-----------------------------------\n## Fold 3\n-----------------------------------\ntrn_idx len is 782\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.47085745521560124\n-----------------------------------\nOverall CV RMSE = 0.4718961607960865\n-----------------------------------\n## Fold 4\n-----------------------------------\ntrn_idx len is 783\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.47072768676529914\n-----------------------------------\nOverall CV RMSE = 0.4716961273350701\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_data\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:27:04.371777Z","iopub.execute_input":"2022-11-30T00:27:04.372442Z","iopub.status.idle":"2022-11-30T00:27:04.601151Z","shell.execute_reply.started":"2022-11-30T00:27:04.372391Z","shell.execute_reply":"2022-11-30T00:27:04.600140Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Model inference on Balanced Test","metadata":{}},{"cell_type":"code","source":"test_data = pretrain_embeddings('distilrobertabase', test)\n\n#test_data = np.concatenate([test_data, pretrain_embeddings('bertbasecased', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertabase', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertalarge', test)], axis=1)\n\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:27:04.602863Z","iopub.execute_input":"2022-11-30T00:27:04.603207Z","iopub.status.idle":"2022-11-30T00:30:58.685514Z","shell.execute_reply.started":"2022-11-30T00:27:04.603172Z","shell.execute_reply":"2022-11-30T00:30:58.684495Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_3 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_3 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_3 (TFOpLambda)   (None, 512, 1)       0           tf.cast_3[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_3 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_3[0][6]         \n                                                                 tf.expand_dims_3[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_7 (TFOpLambd (None, 1)            0           tf.expand_dims_3[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_6 (TFOpLambd (None, 768)          0           tf.math.multiply_3[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_3 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_7[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_3 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_6[0][0]       \n                                                                 tf.math.maximum_3[0][0]          \n__________________________________________________________________________________________________\ntf.stack_3 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_3[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_3 (TFOpLam (None, 768)          0           tf.stack_3[0][0]                 \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_4 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_4 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_4 (TFOpLambda)   (None, 512, 1)       0           tf.cast_4[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_4 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_4[0][12]        \n                                                                 tf.expand_dims_4[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_9 (TFOpLambd (None, 1)            0           tf.expand_dims_4[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_8 (TFOpLambd (None, 768)          0           tf.math.multiply_4[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_4 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_9[0][0]       \n__________________________________________________________________________________________________\ntf.math.truediv_4 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_8[0][0]       \n                                                                 tf.math.maximum_4[0][0]          \n__________________________________________________________________________________________________\ntf.stack_4 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_4[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_4 (TFOpLam (None, 768)          0           tf.stack_4[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_5 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_5 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_5 (TFOpLambda)   (None, 512, 1)       0           tf.cast_5[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_5 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_5[0][24]        \n                                                                 tf.expand_dims_5[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_11 (TFOpLamb (None, 1)            0           tf.expand_dims_5[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_10 (TFOpLamb (None, 1024)         0           tf.math.multiply_5[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_5 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_11[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_5 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_10[0][0]      \n                                                                 tf.math.maximum_5[0][0]          \n__________________________________________________________________________________________________\ntf.stack_5 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_5[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_5 (TFOpLam (None, 1024)         0           tf.stack_5[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(783, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"fold_preds = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('-'*35)\n    print(f'## Fold {fold}')\n    print('-'*35)\n    \n    test_preds = np.zeros((len(test_data),6))\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        model = pickle_load(f\"./SVR_tgt{tgt}_fold{fold}.pkl\")\n        test_preds[:,i] = model.predict(test_data)\n    \n    fold_preds.append(test_preds)\n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('-'*35)\n    print('Overall CV RMSE =',np.mean(scores))\n    \n    del model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:30:58.687239Z","iopub.execute_input":"2022-11-30T00:30:58.687925Z","iopub.status.idle":"2022-11-30T00:31:19.332415Z","shell.execute_reply.started":"2022-11-30T00:30:58.687890Z","shell.execute_reply":"2022-11-30T00:31:19.331370Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"-----------------------------------\n## Fold 1\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.4706498256951178\n-----------------------------------\nOverall CV RMSE = 0.47154122214356003\n-----------------------------------\n## Fold 2\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.47059791831499687\n-----------------------------------\nOverall CV RMSE = 0.4714197885054357\n-----------------------------------\n## Fold 3\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.4705608416149106\n-----------------------------------\nOverall CV RMSE = 0.47132239286579874\n-----------------------------------\n## Fold 4\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.47053303408984587\n-----------------------------------\nOverall CV RMSE = 0.47124255965677436\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.mean(fold_preds, axis=0)\npreds = np.clip(preds, 1, 5)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:19.334441Z","iopub.execute_input":"2022-11-30T00:31:19.335491Z","iopub.status.idle":"2022-11-30T00:31:19.341279Z","shell.execute_reply.started":"2022-11-30T00:31:19.335453Z","shell.execute_reply":"2022-11-30T00:31:19.340327Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"output_df = test[['text_id']].reset_index()\noutput_df","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:19.342792Z","iopub.execute_input":"2022-11-30T00:31:19.343169Z","iopub.status.idle":"2022-11-30T00:31:19.362387Z","shell.execute_reply.started":"2022-11-30T00:31:19.343134Z","shell.execute_reply":"2022-11-30T00:31:19.361256Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"     index       text_id\n0        0  13C400DD9794\n1        1  D9BC7F4F22F0\n2        2  3E170458E9A1\n3        3  E0BFF1488787\n4        4  C50BE3C76571\n..     ...           ...\n778    778  A4A90A401002\n779    779  CA11FD3CAC43\n780    780  0BB9FAE6E27B\n781    781  ED0A8E614649\n782    782  ACA1A45EE438\n\n[783 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>13C400DD9794</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>D9BC7F4F22F0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3E170458E9A1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>E0BFF1488787</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>C50BE3C76571</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>778</td>\n      <td>A4A90A401002</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>779</td>\n      <td>CA11FD3CAC43</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>780</td>\n      <td>0BB9FAE6E27B</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>781</td>\n      <td>ED0A8E614649</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>782</td>\n      <td>ACA1A45EE438</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df = pd.DataFrame(preds, columns = tgtCols)\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:19.363925Z","iopub.execute_input":"2022-11-30T00:31:19.364338Z","iopub.status.idle":"2022-11-30T00:31:19.384201Z","shell.execute_reply.started":"2022-11-30T00:31:19.364304Z","shell.execute_reply":"2022-11-30T00:31:19.383130Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"     cohesion    syntax  vocabulary  phraseology   grammar  conventions\n0    1.800074  1.804792    2.178533     1.920928  1.800869     1.883982\n1    2.748422  2.644605    2.971835     2.792340  2.528817     2.422574\n2    1.938913  1.796602    2.284502     1.923307  1.714191     2.035963\n3    2.479802  2.568310    2.683838     2.774912  2.789020     2.794571\n4    2.273604  2.116479    2.342235     2.043774  1.933587     2.087017\n..        ...       ...         ...          ...       ...          ...\n778  3.629048  3.534972    3.808915     3.730619  3.613037     3.660695\n779  3.804959  3.595449    3.729805     3.638323  3.525637     3.746667\n780  3.524233  3.557455    3.792438     3.612432  3.485740     3.649140\n781  3.802464  3.574562    3.808553     3.664019  3.454725     3.546447\n782  3.575714  3.514809    3.334503     3.560459  3.622044     3.676185\n\n[783 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.800074</td>\n      <td>1.804792</td>\n      <td>2.178533</td>\n      <td>1.920928</td>\n      <td>1.800869</td>\n      <td>1.883982</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.748422</td>\n      <td>2.644605</td>\n      <td>2.971835</td>\n      <td>2.792340</td>\n      <td>2.528817</td>\n      <td>2.422574</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.938913</td>\n      <td>1.796602</td>\n      <td>2.284502</td>\n      <td>1.923307</td>\n      <td>1.714191</td>\n      <td>2.035963</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.479802</td>\n      <td>2.568310</td>\n      <td>2.683838</td>\n      <td>2.774912</td>\n      <td>2.789020</td>\n      <td>2.794571</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.273604</td>\n      <td>2.116479</td>\n      <td>2.342235</td>\n      <td>2.043774</td>\n      <td>1.933587</td>\n      <td>2.087017</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>3.629048</td>\n      <td>3.534972</td>\n      <td>3.808915</td>\n      <td>3.730619</td>\n      <td>3.613037</td>\n      <td>3.660695</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>3.804959</td>\n      <td>3.595449</td>\n      <td>3.729805</td>\n      <td>3.638323</td>\n      <td>3.525637</td>\n      <td>3.746667</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>3.524233</td>\n      <td>3.557455</td>\n      <td>3.792438</td>\n      <td>3.612432</td>\n      <td>3.485740</td>\n      <td>3.649140</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>3.802464</td>\n      <td>3.574562</td>\n      <td>3.808553</td>\n      <td>3.664019</td>\n      <td>3.454725</td>\n      <td>3.546447</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>3.575714</td>\n      <td>3.514809</td>\n      <td>3.334503</td>\n      <td>3.560459</td>\n      <td>3.622044</td>\n      <td>3.676185</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df['text_id'] = output_df['text_id']\npreds_df = preds_df.reindex(['text_id', *preds_df.columns], axis=1).iloc[: , :-1]\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:19.385671Z","iopub.execute_input":"2022-11-30T00:31:19.386058Z","iopub.status.idle":"2022-11-30T00:31:19.408012Z","shell.execute_reply.started":"2022-11-30T00:31:19.386025Z","shell.execute_reply":"2022-11-30T00:31:19.407073Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"          text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0    13C400DD9794  1.800074  1.804792    2.178533     1.920928  1.800869   \n1    D9BC7F4F22F0  2.748422  2.644605    2.971835     2.792340  2.528817   \n2    3E170458E9A1  1.938913  1.796602    2.284502     1.923307  1.714191   \n3    E0BFF1488787  2.479802  2.568310    2.683838     2.774912  2.789020   \n4    C50BE3C76571  2.273604  2.116479    2.342235     2.043774  1.933587   \n..            ...       ...       ...         ...          ...       ...   \n778  A4A90A401002  3.629048  3.534972    3.808915     3.730619  3.613037   \n779  CA11FD3CAC43  3.804959  3.595449    3.729805     3.638323  3.525637   \n780  0BB9FAE6E27B  3.524233  3.557455    3.792438     3.612432  3.485740   \n781  ED0A8E614649  3.802464  3.574562    3.808553     3.664019  3.454725   \n782  ACA1A45EE438  3.575714  3.514809    3.334503     3.560459  3.622044   \n\n     conventions  \n0       1.883982  \n1       2.422574  \n2       2.035963  \n3       2.794571  \n4       2.087017  \n..           ...  \n778     3.660695  \n779     3.746667  \n780     3.649140  \n781     3.546447  \n782     3.676185  \n\n[783 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13C400DD9794</td>\n      <td>1.800074</td>\n      <td>1.804792</td>\n      <td>2.178533</td>\n      <td>1.920928</td>\n      <td>1.800869</td>\n      <td>1.883982</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D9BC7F4F22F0</td>\n      <td>2.748422</td>\n      <td>2.644605</td>\n      <td>2.971835</td>\n      <td>2.792340</td>\n      <td>2.528817</td>\n      <td>2.422574</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3E170458E9A1</td>\n      <td>1.938913</td>\n      <td>1.796602</td>\n      <td>2.284502</td>\n      <td>1.923307</td>\n      <td>1.714191</td>\n      <td>2.035963</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E0BFF1488787</td>\n      <td>2.479802</td>\n      <td>2.568310</td>\n      <td>2.683838</td>\n      <td>2.774912</td>\n      <td>2.789020</td>\n      <td>2.794571</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>C50BE3C76571</td>\n      <td>2.273604</td>\n      <td>2.116479</td>\n      <td>2.342235</td>\n      <td>2.043774</td>\n      <td>1.933587</td>\n      <td>2.087017</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>A4A90A401002</td>\n      <td>3.629048</td>\n      <td>3.534972</td>\n      <td>3.808915</td>\n      <td>3.730619</td>\n      <td>3.613037</td>\n      <td>3.660695</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>CA11FD3CAC43</td>\n      <td>3.804959</td>\n      <td>3.595449</td>\n      <td>3.729805</td>\n      <td>3.638323</td>\n      <td>3.525637</td>\n      <td>3.746667</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>0BB9FAE6E27B</td>\n      <td>3.524233</td>\n      <td>3.557455</td>\n      <td>3.792438</td>\n      <td>3.612432</td>\n      <td>3.485740</td>\n      <td>3.649140</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>ED0A8E614649</td>\n      <td>3.802464</td>\n      <td>3.574562</td>\n      <td>3.808553</td>\n      <td>3.664019</td>\n      <td>3.454725</td>\n      <td>3.546447</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>ACA1A45EE438</td>\n      <td>3.575714</td>\n      <td>3.514809</td>\n      <td>3.334503</td>\n      <td>3.560459</td>\n      <td>3.622044</td>\n      <td>3.676185</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df.to_csv('tesths.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:19.409246Z","iopub.execute_input":"2022-11-30T00:31:19.410177Z","iopub.status.idle":"2022-11-30T00:31:19.431163Z","shell.execute_reply.started":"2022-11-30T00:31:19.410144Z","shell.execute_reply":"2022-11-30T00:31:19.430300Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Running the final text dataset","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/580data/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:19.432926Z","iopub.execute_input":"2022-11-30T00:31:19.433361Z","iopub.status.idle":"2022-11-30T00:31:19.446291Z","shell.execute_reply.started":"2022-11-30T00:31:19.433326Z","shell.execute_reply":"2022-11-30T00:31:19.445302Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"test_data = pretrain_embeddings('distilrobertabase', test)\n\n#test_data = np.concatenate([test_data, pretrain_embeddings('bertbasecased', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertabase', test)], axis=1)\ntest_data = np.concatenate([test_data, pretrain_embeddings('robertalarge', test)], axis=1)\n\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:19.447792Z","iopub.execute_input":"2022-11-30T00:31:19.448327Z","iopub.status.idle":"2022-11-30T00:31:55.664607Z","shell.execute_reply.started":"2022-11-30T00:31:19.448279Z","shell.execute_reply":"2022-11-30T00:31:55.663582Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Model: \"model_6\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_6 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_6 (TFRobertaMo TFBaseModelOutputWit 82118400    input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_6 (TFOpLambda)   (None, 512, 1)       0           tf.cast_6[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_6 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_6[0][6]         \n                                                                 tf.expand_dims_6[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_13 (TFOpLamb (None, 1)            0           tf.expand_dims_6[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_12 (TFOpLamb (None, 768)          0           tf.math.multiply_6[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_6 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_13[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_6 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_12[0][0]      \n                                                                 tf.math.maximum_6[0][0]          \n__________________________________________________________________________________________________\ntf.stack_6 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_6[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_6 (TFOpLam (None, 768)          0           tf.stack_6[0][0]                 \n==================================================================================================\nTotal params: 82,118,400\nTrainable params: 82,118,400\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_7 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_7 (TFRobertaMo TFBaseModelOutputWit 124645632   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_7 (TFOpLambda)   (None, 512, 1)       0           tf.cast_7[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_7 (TFOpLambda) (None, 512, 768)     0           tf_roberta_model_7[0][12]        \n                                                                 tf.expand_dims_7[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_15 (TFOpLamb (None, 1)            0           tf.expand_dims_7[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_14 (TFOpLamb (None, 768)          0           tf.math.multiply_7[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_7 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_15[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_7 (TFOpLambda)  (None, 768)          0           tf.math.reduce_sum_14[0][0]      \n                                                                 tf.math.maximum_7[0][0]          \n__________________________________________________________________________________________________\ntf.stack_7 (TFOpLambda)         (None, 768, 1)       0           tf.math.truediv_7[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_7 (TFOpLam (None, 768)          0           tf.stack_7[0][0]                 \n==================================================================================================\nTotal params: 124,645,632\nTrainable params: 124,645,632\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nModel: \"model_8\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf.cast_8 (TFOpLambda)          (None, 512)          0           attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf_roberta_model_8 (TFRobertaMo TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.expand_dims_8 (TFOpLambda)   (None, 512, 1)       0           tf.cast_8[0][0]                  \n__________________________________________________________________________________________________\ntf.math.multiply_8 (TFOpLambda) (None, 512, 1024)    0           tf_roberta_model_8[0][24]        \n                                                                 tf.expand_dims_8[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_17 (TFOpLamb (None, 1)            0           tf.expand_dims_8[0][0]           \n__________________________________________________________________________________________________\ntf.math.reduce_sum_16 (TFOpLamb (None, 1024)         0           tf.math.multiply_8[0][0]         \n__________________________________________________________________________________________________\ntf.math.maximum_8 (TFOpLambda)  (None, 1)            0           tf.math.reduce_sum_17[0][0]      \n__________________________________________________________________________________________________\ntf.math.truediv_8 (TFOpLambda)  (None, 1024)         0           tf.math.reduce_sum_16[0][0]      \n                                                                 tf.math.maximum_8[0][0]          \n__________________________________________________________________________________________________\ntf.stack_8 (TFOpLambda)         (None, 1024, 1)      0           tf.math.truediv_8[0][0]          \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze_8 (TFOpLam (None, 1024)         0           tf.stack_8[0][0]                 \n==================================================================================================\nTotal params: 355,359,744\nTrainable params: 355,359,744\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(8, 2560)"},"metadata":{}}]},{"cell_type":"code","source":"fold_preds = []\n\nfor fold in range(1,CONFIG['folds']):\n\n    print('-'*35)\n    print(f'## Fold {fold}')\n    print('-'*35)\n    \n    test_preds = np.zeros((len(test_data),6))\n    for i, tgt in enumerate(tgtCols):\n\n        print(tgt,', ',end='')\n        model = pickle_load(f\"./SVR_tgt{tgt}_fold{fold}.pkl\")\n        test_preds[:,i] = model.predict(test_data)\n    \n    fold_preds.append(test_preds)\n    \n    for i in range(len(tgtCols)):\n        rmse_scores.append(np.sqrt(mean_squared_error(y_valid[tgtCols].values[:,i],val_preds[:,i])))\n        score = np.mean(rmse_scores)\n    #score = mcrmse(y_valid[tgtCols].values, val_preds)\n        scores.append(score)\n    print(\"Fold : {} RMSE score: {}\".format(fold,score))\n\n    print('-'*35)\n    print('Overall CV RMSE =',np.mean(scores))\n    \n    del model\n    _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:55.666251Z","iopub.execute_input":"2022-11-30T00:31:55.666606Z","iopub.status.idle":"2022-11-30T00:31:57.054355Z","shell.execute_reply.started":"2022-11-30T00:31:55.666572Z","shell.execute_reply":"2022-11-30T00:31:57.053495Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"-----------------------------------\n## Fold 1\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 1 RMSE score: 0.4705114060147955\n-----------------------------------\nOverall CV RMSE = 0.47117587938357997\n-----------------------------------\n## Fold 2\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 2 RMSE score: 0.47049410355475524\n-----------------------------------\nOverall CV RMSE = 0.4711192888782515\n-----------------------------------\n## Fold 3\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 3 RMSE score: 0.4704799469965404\n-----------------------------------\nOverall CV RMSE = 0.4710706062021693\n-----------------------------------\n## Fold 4\n-----------------------------------\ncohesion , syntax , vocabulary , phraseology , grammar , conventions , Fold : 4 RMSE score: 0.4704681498646947\n-----------------------------------\nOverall CV RMSE = 0.4710282386845602\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.mean(fold_preds, axis=0)\npreds = np.clip(preds, 1, 5)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:57.058502Z","iopub.execute_input":"2022-11-30T00:31:57.060680Z","iopub.status.idle":"2022-11-30T00:31:57.067597Z","shell.execute_reply.started":"2022-11-30T00:31:57.060640Z","shell.execute_reply":"2022-11-30T00:31:57.066604Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"preds_df = pd.DataFrame(preds, columns = tgtCols)\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:57.071943Z","iopub.execute_input":"2022-11-30T00:31:57.074004Z","iopub.status.idle":"2022-11-30T00:31:57.094721Z","shell.execute_reply.started":"2022-11-30T00:31:57.073968Z","shell.execute_reply":"2022-11-30T00:31:57.093830Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   cohesion    syntax  vocabulary  phraseology   grammar  conventions\n0  2.838727  2.748008    3.025828     2.893462  2.601690     2.597918\n1  2.722521  2.461244    2.749818     2.476476  2.115154     2.622110\n2  3.460912  3.354621    3.550451     3.457997  3.360515     3.341161\n3  3.277663  3.249178    3.499111     3.319013  3.306077     3.027291\n4  3.730765  3.690547    3.956144     3.722939  3.635976     3.484476\n5  3.706104  3.621633    3.981173     3.628974  3.575151     3.778684\n6  3.866864  3.803552    4.026429     3.899598  3.796488     3.807109\n7  4.073992  3.844181    4.063811     3.883764  3.765704     3.903198","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.838727</td>\n      <td>2.748008</td>\n      <td>3.025828</td>\n      <td>2.893462</td>\n      <td>2.601690</td>\n      <td>2.597918</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.722521</td>\n      <td>2.461244</td>\n      <td>2.749818</td>\n      <td>2.476476</td>\n      <td>2.115154</td>\n      <td>2.622110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.460912</td>\n      <td>3.354621</td>\n      <td>3.550451</td>\n      <td>3.457997</td>\n      <td>3.360515</td>\n      <td>3.341161</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.277663</td>\n      <td>3.249178</td>\n      <td>3.499111</td>\n      <td>3.319013</td>\n      <td>3.306077</td>\n      <td>3.027291</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.730765</td>\n      <td>3.690547</td>\n      <td>3.956144</td>\n      <td>3.722939</td>\n      <td>3.635976</td>\n      <td>3.484476</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.706104</td>\n      <td>3.621633</td>\n      <td>3.981173</td>\n      <td>3.628974</td>\n      <td>3.575151</td>\n      <td>3.778684</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.866864</td>\n      <td>3.803552</td>\n      <td>4.026429</td>\n      <td>3.899598</td>\n      <td>3.796488</td>\n      <td>3.807109</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4.073992</td>\n      <td>3.844181</td>\n      <td>4.063811</td>\n      <td>3.883764</td>\n      <td>3.765704</td>\n      <td>3.903198</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output_df = test[['text_id']].reset_index()\noutput_df","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:57.098993Z","iopub.execute_input":"2022-11-30T00:31:57.101063Z","iopub.status.idle":"2022-11-30T00:31:57.115570Z","shell.execute_reply.started":"2022-11-30T00:31:57.101031Z","shell.execute_reply":"2022-11-30T00:31:57.114816Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"   index       text_id\n0      0  0000C359D63E\n1      1  000BAD50D026\n2      2  00367BB2546B\n3      3            hp\n4      4           tkm\n5      5   high school\n6      6      college1\n7      7      college2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0000C359D63E</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>000BAD50D026</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>00367BB2546B</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>hp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>tkm</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>high school</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>college1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>college2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df['text_id'] = output_df['text_id']\npreds_df = preds_df.reindex(['text_id', *preds_df.columns], axis=1).iloc[: , :-1]\npreds_df","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:57.119184Z","iopub.execute_input":"2022-11-30T00:31:57.121522Z","iopub.status.idle":"2022-11-30T00:31:57.142766Z","shell.execute_reply.started":"2022-11-30T00:31:57.121489Z","shell.execute_reply":"2022-11-30T00:31:57.142009Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0  0000C359D63E  2.838727  2.748008    3.025828     2.893462  2.601690   \n1  000BAD50D026  2.722521  2.461244    2.749818     2.476476  2.115154   \n2  00367BB2546B  3.460912  3.354621    3.550451     3.457997  3.360515   \n3            hp  3.277663  3.249178    3.499111     3.319013  3.306077   \n4           tkm  3.730765  3.690547    3.956144     3.722939  3.635976   \n5   high school  3.706104  3.621633    3.981173     3.628974  3.575151   \n6      college1  3.866864  3.803552    4.026429     3.899598  3.796488   \n7      college2  4.073992  3.844181    4.063811     3.883764  3.765704   \n\n   conventions  \n0     2.597918  \n1     2.622110  \n2     3.341161  \n3     3.027291  \n4     3.484476  \n5     3.778684  \n6     3.807109  \n7     3.903198  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>2.838727</td>\n      <td>2.748008</td>\n      <td>3.025828</td>\n      <td>2.893462</td>\n      <td>2.601690</td>\n      <td>2.597918</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>2.722521</td>\n      <td>2.461244</td>\n      <td>2.749818</td>\n      <td>2.476476</td>\n      <td>2.115154</td>\n      <td>2.622110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.460912</td>\n      <td>3.354621</td>\n      <td>3.550451</td>\n      <td>3.457997</td>\n      <td>3.360515</td>\n      <td>3.341161</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hp</td>\n      <td>3.277663</td>\n      <td>3.249178</td>\n      <td>3.499111</td>\n      <td>3.319013</td>\n      <td>3.306077</td>\n      <td>3.027291</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tkm</td>\n      <td>3.730765</td>\n      <td>3.690547</td>\n      <td>3.956144</td>\n      <td>3.722939</td>\n      <td>3.635976</td>\n      <td>3.484476</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>high school</td>\n      <td>3.706104</td>\n      <td>3.621633</td>\n      <td>3.981173</td>\n      <td>3.628974</td>\n      <td>3.575151</td>\n      <td>3.778684</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>college1</td>\n      <td>3.866864</td>\n      <td>3.803552</td>\n      <td>4.026429</td>\n      <td>3.899598</td>\n      <td>3.796488</td>\n      <td>3.807109</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>college2</td>\n      <td>4.073992</td>\n      <td>3.844181</td>\n      <td>4.063811</td>\n      <td>3.883764</td>\n      <td>3.765704</td>\n      <td>3.903198</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds_df.to_csv('hsfinal.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:57.146356Z","iopub.execute_input":"2022-11-30T00:31:57.147243Z","iopub.status.idle":"2022-11-30T00:31:57.154270Z","shell.execute_reply.started":"2022-11-30T00:31:57.147210Z","shell.execute_reply":"2022-11-30T00:31:57.153488Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Running SVR after TF-IDF","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error as mse\nimport math\nfrom sklearn.svm import SVR","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:44:59.993413Z","iopub.execute_input":"2022-11-30T14:44:59.994436Z","iopub.status.idle":"2022-11-30T14:45:00.111152Z","shell.execute_reply.started":"2022-11-30T14:44:59.994398Z","shell.execute_reply":"2022-11-30T14:45:00.110185Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Model inference on Balanced Test","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/580data/train_balanced.csv\")\ntest = pd.read_csv(\"/kaggle/input/580data/test_balanced.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:50:29.398116Z","iopub.execute_input":"2022-11-30T14:50:29.398542Z","iopub.status.idle":"2022-11-30T14:50:29.490604Z","shell.execute_reply.started":"2022-11-30T14:50:29.398509Z","shell.execute_reply":"2022-11-30T14:50:29.489521Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"full_df = np.concatenate((train.full_text.values,test.full_text.values))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:50:30.660350Z","iopub.execute_input":"2022-11-30T14:50:30.661021Z","iopub.status.idle":"2022-11-30T14:50:30.666673Z","shell.execute_reply.started":"2022-11-30T14:50:30.660987Z","shell.execute_reply":"2022-11-30T14:50:30.665729Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tfidf_featurizer = TfidfVectorizer(max_features=10000, max_df=0.98, stop_words='english')\nX_tfidf = tfidf_featurizer.fit_transform(full_df)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:50:31.925820Z","iopub.execute_input":"2022-11-30T14:50:31.926201Z","iopub.status.idle":"2022-11-30T14:50:32.805772Z","shell.execute_reply.started":"2022-11-30T14:50:31.926153Z","shell.execute_reply":"2022-11-30T14:50:32.804673Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# SPLIT DATA\ntgtCols = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\nX_train, X_test, y_train, y_test = train_test_split(X_tfidf[0:len(train.full_text)], \n                                                    train[tgtCols].values,\n                                                    test_size=0.10,\n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:50:34.775048Z","iopub.execute_input":"2022-11-30T14:50:34.775431Z","iopub.status.idle":"2022-11-30T14:50:34.786988Z","shell.execute_reply.started":"2022-11-30T14:50:34.775400Z","shell.execute_reply":"2022-11-30T14:50:34.785945Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:50:36.062640Z","iopub.execute_input":"2022-11-30T14:50:36.063355Z","iopub.status.idle":"2022-11-30T14:50:36.069952Z","shell.execute_reply.started":"2022-11-30T14:50:36.063310Z","shell.execute_reply":"2022-11-30T14:50:36.068944Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"(2815, 10000)\n(313, 10000)\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params = {'C' : 10, \n                'epsilon': 0.1, \n                'gamma' : 1, \n                'kernel' : 'rbf'} ","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:50:37.556517Z","iopub.execute_input":"2022-11-30T14:50:37.556957Z","iopub.status.idle":"2022-11-30T14:50:37.563851Z","shell.execute_reply.started":"2022-11-30T14:50:37.556918Z","shell.execute_reply":"2022-11-30T14:50:37.562742Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"data_test = X_tfidf[len(train.full_text):]\ndf_sum = pd.DataFrame([],index=test.text_id,columns= tgtCols)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:50:40.584893Z","iopub.execute_input":"2022-11-30T14:50:40.585252Z","iopub.status.idle":"2022-11-30T14:50:40.594098Z","shell.execute_reply.started":"2022-11-30T14:50:40.585220Z","shell.execute_reply":"2022-11-30T14:50:40.593232Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nrerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(X_test)\n  rerror.append(mse(rf_preds,y_test[:,k]))\n  MSE = np.mean(rerror)\n  RMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:50:43.942466Z","iopub.execute_input":"2022-11-30T14:50:43.942837Z","iopub.status.idle":"2022-11-30T14:51:25.018625Z","shell.execute_reply.started":"2022-11-30T14:50:43.942808Z","shell.execute_reply":"2022-11-30T14:51:25.017513Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Root Mean Square Error:\n\n0.6059682633613659\n","output_type":"stream"}]},{"cell_type":"code","source":"test_test = test.iloc[0:,3:9]\ntest_test","metadata":{"execution":{"iopub.status.busy":"2022-11-30T15:01:16.046937Z","iopub.execute_input":"2022-11-30T15:01:16.047384Z","iopub.status.idle":"2022-11-30T15:01:16.099206Z","shell.execute_reply.started":"2022-11-30T15:01:16.047347Z","shell.execute_reply":"2022-11-30T15:01:16.098333Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"     cohesion  syntax  vocabulary  phraseology  grammar  conventions\n0         2.0     2.0         2.0          2.0      2.0          2.0\n1         2.5     2.5         2.5          3.0      2.5          2.0\n2         2.0     2.0         2.0          2.0      2.0          2.5\n3         2.5     2.0         2.5          2.0      2.0          2.5\n4         3.0     2.5         2.0          2.0      2.0          2.5\n..        ...     ...         ...          ...      ...          ...\n778       3.0     3.5         3.5          4.0      3.5          4.0\n779       4.5     4.0         3.5          4.0      3.5          3.5\n780       3.5     4.0         4.5          4.0      3.5          3.5\n781       4.5     3.5         4.0          4.0      4.0          3.5\n782       4.0     3.0         3.0          4.0      4.0          4.0\n\n[783 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>4.5</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"testarray = test_test.to_numpy()\ntestarray[0]","metadata":{"execution":{"iopub.status.busy":"2022-11-30T15:01:19.238612Z","iopub.execute_input":"2022-11-30T15:01:19.239073Z","iopub.status.idle":"2022-11-30T15:01:19.247852Z","shell.execute_reply.started":"2022-11-30T15:01:19.239030Z","shell.execute_reply":"2022-11-30T15:01:19.246529Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"array([2., 2., 2., 2., 2., 2.])"},"metadata":{}}]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(data_test)\n  #print(rf_preds)\n  df_sum[tgtCols[k]] = rf_preds\n  rerror.append(mse(rf_preds,testarray[:,k]))\n  MSE = np.mean(rerror)\n  RMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)\n  #error.append(rmse(rf_preds,y_test[:,k],squared=False))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T15:07:12.424379Z","iopub.execute_input":"2022-11-30T15:07:12.425182Z","iopub.status.idle":"2022-11-30T15:07:58.597135Z","shell.execute_reply.started":"2022-11-30T15:07:12.425139Z","shell.execute_reply":"2022-11-30T15:07:58.596061Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Root Mean Square Error:\n\n0.5811373724702388\n","output_type":"stream"}]},{"cell_type":"code","source":"df_sum","metadata":{"execution":{"iopub.status.busy":"2022-11-30T15:07:58.599953Z","iopub.execute_input":"2022-11-30T15:07:58.600320Z","iopub.status.idle":"2022-11-30T15:07:58.618341Z","shell.execute_reply.started":"2022-11-30T15:07:58.600290Z","shell.execute_reply":"2022-11-30T15:07:58.617340Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"              cohesion    syntax  vocabulary  phraseology   grammar  \\\ntext_id                                                               \n13C400DD9794  2.853360  2.850215    2.848165     2.837042  3.005184   \nD9BC7F4F22F0  2.737378  2.419024    2.698912     2.476842  2.503007   \n3E170458E9A1  2.740506  2.642922    2.872641     2.793128  2.755787   \nE0BFF1488787  2.786685  2.850549    2.972727     2.767457  2.806187   \nC50BE3C76571  2.732530  2.602709    2.823353     2.491031  2.213038   \n...                ...       ...         ...          ...       ...   \nA4A90A401002  3.376377  3.209147    3.556211     3.173799  3.539506   \nCA11FD3CAC43  3.719921  3.441376    3.739208     3.654375  3.216852   \n0BB9FAE6E27B  3.354057  3.210798    3.567047     3.134979  3.391220   \nED0A8E614649  3.361802  3.370543    3.564252     3.569192  3.271189   \nACA1A45EE438  3.450626  3.321926    3.468081     3.269563  3.511854   \n\n              conventions  \ntext_id                    \n13C400DD9794     2.759427  \nD9BC7F4F22F0     2.221925  \n3E170458E9A1     2.731921  \nE0BFF1488787     3.038367  \nC50BE3C76571     2.485433  \n...                   ...  \nA4A90A401002     3.412993  \nCA11FD3CAC43     3.539730  \n0BB9FAE6E27B     3.483420  \nED0A8E614649     3.454624  \nACA1A45EE438     3.542166  \n\n[783 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n    <tr>\n      <th>text_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13C400DD9794</th>\n      <td>2.853360</td>\n      <td>2.850215</td>\n      <td>2.848165</td>\n      <td>2.837042</td>\n      <td>3.005184</td>\n      <td>2.759427</td>\n    </tr>\n    <tr>\n      <th>D9BC7F4F22F0</th>\n      <td>2.737378</td>\n      <td>2.419024</td>\n      <td>2.698912</td>\n      <td>2.476842</td>\n      <td>2.503007</td>\n      <td>2.221925</td>\n    </tr>\n    <tr>\n      <th>3E170458E9A1</th>\n      <td>2.740506</td>\n      <td>2.642922</td>\n      <td>2.872641</td>\n      <td>2.793128</td>\n      <td>2.755787</td>\n      <td>2.731921</td>\n    </tr>\n    <tr>\n      <th>E0BFF1488787</th>\n      <td>2.786685</td>\n      <td>2.850549</td>\n      <td>2.972727</td>\n      <td>2.767457</td>\n      <td>2.806187</td>\n      <td>3.038367</td>\n    </tr>\n    <tr>\n      <th>C50BE3C76571</th>\n      <td>2.732530</td>\n      <td>2.602709</td>\n      <td>2.823353</td>\n      <td>2.491031</td>\n      <td>2.213038</td>\n      <td>2.485433</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>A4A90A401002</th>\n      <td>3.376377</td>\n      <td>3.209147</td>\n      <td>3.556211</td>\n      <td>3.173799</td>\n      <td>3.539506</td>\n      <td>3.412993</td>\n    </tr>\n    <tr>\n      <th>CA11FD3CAC43</th>\n      <td>3.719921</td>\n      <td>3.441376</td>\n      <td>3.739208</td>\n      <td>3.654375</td>\n      <td>3.216852</td>\n      <td>3.539730</td>\n    </tr>\n    <tr>\n      <th>0BB9FAE6E27B</th>\n      <td>3.354057</td>\n      <td>3.210798</td>\n      <td>3.567047</td>\n      <td>3.134979</td>\n      <td>3.391220</td>\n      <td>3.483420</td>\n    </tr>\n    <tr>\n      <th>ED0A8E614649</th>\n      <td>3.361802</td>\n      <td>3.370543</td>\n      <td>3.564252</td>\n      <td>3.569192</td>\n      <td>3.271189</td>\n      <td>3.454624</td>\n    </tr>\n    <tr>\n      <th>ACA1A45EE438</th>\n      <td>3.450626</td>\n      <td>3.321926</td>\n      <td>3.468081</td>\n      <td>3.269563</td>\n      <td>3.511854</td>\n      <td>3.542166</td>\n    </tr>\n  </tbody>\n</table>\n<p>783 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_sum.to_csv('svrtest.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-30T15:07:58.619685Z","iopub.execute_input":"2022-11-30T15:07:58.621783Z","iopub.status.idle":"2022-11-30T15:07:58.637325Z","shell.execute_reply.started":"2022-11-30T15:07:58.621676Z","shell.execute_reply":"2022-11-30T15:07:58.636495Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"## Model inference on Final Test","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/feedback-prize-english-language-learning/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/580data/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:47:31.911174Z","iopub.execute_input":"2022-11-30T14:47:31.911820Z","iopub.status.idle":"2022-11-30T14:47:32.170213Z","shell.execute_reply.started":"2022-11-30T14:47:31.911782Z","shell.execute_reply":"2022-11-30T14:47:32.169250Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Running for the train full_text with training all\n# fit the six test as test\nfull_df = np.concatenate((train.full_text.values,test.full_text.values))","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:47:32.171609Z","iopub.execute_input":"2022-11-30T14:47:32.171988Z","iopub.status.idle":"2022-11-30T14:47:32.179840Z","shell.execute_reply.started":"2022-11-30T14:47:32.171952Z","shell.execute_reply":"2022-11-30T14:47:32.178784Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tfidf_featurizer = TfidfVectorizer(max_features=10000, max_df=0.98, stop_words='english')\nX_tfidf = tfidf_featurizer.fit_transform(full_df)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:47:32.181400Z","iopub.execute_input":"2022-11-30T14:47:32.182073Z","iopub.status.idle":"2022-11-30T14:47:33.101782Z","shell.execute_reply.started":"2022-11-30T14:47:32.182036Z","shell.execute_reply":"2022-11-30T14:47:33.100676Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# SPLIT DATA\nX_train, X_test, y_train, y_test = train_test_split(X_tfidf[0:len(train.full_text)], \n                                                    train[tgtCols].values,\n                                                    test_size=0.10,\n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T14:47:33.103297Z","iopub.execute_input":"2022-11-30T14:47:33.104079Z","iopub.status.idle":"2022-11-30T14:47:33.117067Z","shell.execute_reply.started":"2022-11-30T14:47:33.104028Z","shell.execute_reply":"2022-11-30T14:47:33.115955Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:58.342474Z","iopub.execute_input":"2022-11-30T00:31:58.343128Z","iopub.status.idle":"2022-11-30T00:31:58.352167Z","shell.execute_reply.started":"2022-11-30T00:31:58.343085Z","shell.execute_reply":"2022-11-30T00:31:58.351071Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"(3519, 10000)\n(392, 10000)\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params = {'C' : 10, \n                'epsilon': 0.1, \n                'gamma' : 1, \n                'kernel' : 'rbf'} ","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:58.359508Z","iopub.execute_input":"2022-11-30T00:31:58.360434Z","iopub.status.idle":"2022-11-30T00:31:58.365396Z","shell.execute_reply.started":"2022-11-30T00:31:58.360395Z","shell.execute_reply":"2022-11-30T00:31:58.364165Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"data_test = X_tfidf[len(train.full_text):]\ndf_sum = pd.DataFrame([],index=test.text_id,columns= tgtCols)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:58.367186Z","iopub.execute_input":"2022-11-30T00:31:58.367565Z","iopub.status.idle":"2022-11-30T00:31:58.376415Z","shell.execute_reply.started":"2022-11-30T00:31:58.367530Z","shell.execute_reply":"2022-11-30T00:31:58.375304Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nrerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(X_test)\n  rerror.append(mse(rf_preds,y_test[:,k]))\n  MSE = np.mean(rerror)\n  RMSE = math.sqrt(MSE)\nprint(\"Root Mean Square Error:\\n\")\nprint(RMSE)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:31:58.390314Z","iopub.execute_input":"2022-11-30T00:31:58.392841Z","iopub.status.idle":"2022-11-30T00:32:58.603428Z","shell.execute_reply.started":"2022-11-30T00:31:58.392806Z","shell.execute_reply":"2022-11-30T00:32:58.602232Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Root Mean Square Error:\n\n0.5588277727742706\n","output_type":"stream"}]},{"cell_type":"code","source":"svr_clf = SVR(**best_params)\nerror = []\nfor k in range(0,y_train.shape[1]):\n  svr_clf.fit(X_train, y_train[:,k])\n  rf_preds = svr_clf.predict(data_test)\n  df_sum[tgtCols[k]] = rf_preds\n  #error.append(rmse(rf_preds,y_test[:,k],squared=False))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:32:58.604954Z","iopub.execute_input":"2022-11-30T00:32:58.605521Z","iopub.status.idle":"2022-11-30T00:33:53.701738Z","shell.execute_reply.started":"2022-11-30T00:32:58.605484Z","shell.execute_reply":"2022-11-30T00:33:53.700564Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"df_sum","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:33:53.703202Z","iopub.execute_input":"2022-11-30T00:33:53.705927Z","iopub.status.idle":"2022-11-30T00:33:53.719242Z","shell.execute_reply.started":"2022-11-30T00:33:53.705882Z","shell.execute_reply":"2022-11-30T00:33:53.718107Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"              cohesion    syntax  vocabulary  phraseology   grammar  \\\ntext_id                                                               \n0000C359D63E  2.907619  2.724790    3.150306     3.047530  2.636049   \n000BAD50D026  3.000263  2.811820    2.974439     2.673552  2.731733   \n00367BB2546B  3.354401  3.437521    3.444208     3.359888  3.314630   \nhp            2.712970  2.675136    2.985553     2.855222  2.794587   \ntkm           2.822630  2.799316    3.000837     2.851043  2.873569   \nhigh school   2.928985  2.794508    3.178074     2.917375  2.868357   \ncollege1      3.045923  3.017985    3.273694     3.076371  3.009610   \ncollege2      3.026962  2.951940    3.256540     3.008387  2.995780   \n\n              conventions  \ntext_id                    \n0000C359D63E     2.737348  \n000BAD50D026     3.052494  \n00367BB2546B     3.320433  \nhp               2.725889  \ntkm              2.749054  \nhigh school      2.839070  \ncollege1         2.888542  \ncollege2         2.981578  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n    <tr>\n      <th>text_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0000C359D63E</th>\n      <td>2.907619</td>\n      <td>2.724790</td>\n      <td>3.150306</td>\n      <td>3.047530</td>\n      <td>2.636049</td>\n      <td>2.737348</td>\n    </tr>\n    <tr>\n      <th>000BAD50D026</th>\n      <td>3.000263</td>\n      <td>2.811820</td>\n      <td>2.974439</td>\n      <td>2.673552</td>\n      <td>2.731733</td>\n      <td>3.052494</td>\n    </tr>\n    <tr>\n      <th>00367BB2546B</th>\n      <td>3.354401</td>\n      <td>3.437521</td>\n      <td>3.444208</td>\n      <td>3.359888</td>\n      <td>3.314630</td>\n      <td>3.320433</td>\n    </tr>\n    <tr>\n      <th>hp</th>\n      <td>2.712970</td>\n      <td>2.675136</td>\n      <td>2.985553</td>\n      <td>2.855222</td>\n      <td>2.794587</td>\n      <td>2.725889</td>\n    </tr>\n    <tr>\n      <th>tkm</th>\n      <td>2.822630</td>\n      <td>2.799316</td>\n      <td>3.000837</td>\n      <td>2.851043</td>\n      <td>2.873569</td>\n      <td>2.749054</td>\n    </tr>\n    <tr>\n      <th>high school</th>\n      <td>2.928985</td>\n      <td>2.794508</td>\n      <td>3.178074</td>\n      <td>2.917375</td>\n      <td>2.868357</td>\n      <td>2.839070</td>\n    </tr>\n    <tr>\n      <th>college1</th>\n      <td>3.045923</td>\n      <td>3.017985</td>\n      <td>3.273694</td>\n      <td>3.076371</td>\n      <td>3.009610</td>\n      <td>2.888542</td>\n    </tr>\n    <tr>\n      <th>college2</th>\n      <td>3.026962</td>\n      <td>2.951940</td>\n      <td>3.256540</td>\n      <td>3.008387</td>\n      <td>2.995780</td>\n      <td>2.981578</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_sum.to_csv('svr.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:33:53.720746Z","iopub.execute_input":"2022-11-30T00:33:53.721276Z","iopub.status.idle":"2022-11-30T00:33:53.731781Z","shell.execute_reply.started":"2022-11-30T00:33:53.721206Z","shell.execute_reply":"2022-11-30T00:33:53.730821Z"},"trusted":true},"execution_count":47,"outputs":[]}]}